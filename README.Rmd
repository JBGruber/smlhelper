---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%",
  message = FALSE
)
```

# smlhelper

<!-- badges: start -->
[![Travis build status](https://travis-ci.com/JBGruber/smlhelper.svg?branch=master)](https://travis-ci.com/JBGruber/smlhelper)
[![Codecov test coverage](https://codecov.io/gh/JBGruber/smlhelper/branch/master/graph/badge.svg)](https://codecov.io/gh/JBGruber/smlhelper?branch=master)
[![Lifecycle: experimental](https://img.shields.io/badge/lifecycle-experimental-orange.svg)](https://www.tidyverse.org/lifecycle/#experimental)
<!-- badges: end -->

The goal of smlhelper is to help me batch evaluate a number of machine learning algorithms using a number of different preprocessing combinations.

## Installation

If you want to install this, beware that the package is very raw and the target audience so far is just me.

## Example

Construct a list of dfms containing different combinations of preprocessing options:

```{r example}
library(quanteda)
library(smlhelper)
corp <- corpus(c(d1 = "Chinese Beijing Chinese",
                 d2 = "Chinese Chinese Shanghai",
                 d3 = "Chinese Macao",
                 d4 = "Tokyo Japan Chinese",
                 d5 = "Chinese Chinese Chinese Tokyo Japan"))

docvars(corp, "class") <- c(TRUE, TRUE, TRUE, FALSE, FALSE)
docvars(corp, "training") <- c(TRUE, TRUE, TRUE, TRUE, FALSE)

test_dfms <- batch_prep(corp)
```

Now this can be used to run several supervised machine learning algorithms in batch mode on all processing steps:

```{r batch_validate}
results <- batch_validate(x = test_dfms,
                          y = "class",
                          set = "training",
                          alg = list(textmodel_nb = quanteda.textmodels::textmodel_nb,
                                     textmodel_svm = quanteda.textmodels::textmodel_svm),
                          pred = predict)
```

```{r}
library(tidyverse)
results %>% 
  slice_max(order_by = accuracy, n = 10, with_ties = FALSE)
```

# Working SML Algorithms

The `batch_validate` function should work with a large number of algorithms. However, these are the ones I already tested:

```{r tested, echo=FALSE}
tibble::tribble(
  ~package, ~alg, ~pred, ~install,
  "quanteda.textmodels", "textmodel_nb", "predict", "install.packages('quanteda.textmodels')",
  "quanteda.textmodels", "textmodel_svm", "predict", "install.packages('quanteda.textmodels')",
) %>% 
  knitr::kable()
```

